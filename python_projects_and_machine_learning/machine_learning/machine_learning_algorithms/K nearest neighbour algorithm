# Title: K nearest neighbour algorithm
# Author: Otto-Harald Hirvonen
# email: ottoharald.hirvonen@gmail.com
# phone number: 040 41 32 757
# description:
#               This is a practice model of K nearest neighbour algorithm.
#               I used a free dataset from UCI machine learning repository.
#               Some credit goes to an youtube channel called tech with tim
#               from who's recommendations and tutorials I used.


import sklearn
from sklearn.utils import shuffle
from sklearn.neighbors import KNeighborsClassifier
from sklearn import linear_model, preprocessing
import pandas as pd
import numpy as np

data = pd.read_csv("car.data")
print(data.head())

# This is an object that codes our labels into int values
label_enc = preprocessing.LabelEncoder()
# This makes all buying columns into a list and transforms them into int values
buying = label_enc.fit_transform(list(data["buying"])) # returns numpy array [3,3,3,3...1,1,1]
# Same as above for the rest of the variables
maint = label_enc.fit_transform(list(data["maint"]))
doors = label_enc.fit_transform(list(data["doors"]))
persons = label_enc.fit_transform(list(data["persons"]))
lug_boot = label_enc.fit_transform(list(data["lug_boot"]))
safety = label_enc.fit_transform(list(data["safety"]))
cls = label_enc.fit_transform(list(data["class"]))
# ends here

predict = "class"

x = list(zip(buying, maint, doors, persons, lug_boot, safety)) # Returns a list with all the variables in
y = list(cls) # List with all class variables in


x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x, y, test_size=0.1)

print(x_train, y_test)

model = KNeighborsClassifier(n_neighbors=7)
model.fit(x_train, y_train)
acc = model.score(x_test, y_test)
print(acc)

predicted = model.predict(x_test)
names = ["unacc", "acc", "good", "vgood"]

for i in range(len(x_test)):
    print("Predicted: ", names[predicted[i]], "Data: ", x_test[i], "Actual: ", names[y_test[i]])
    n = model.kneighbors([x_test[i]], 7, True)
    print("N: ",n)



